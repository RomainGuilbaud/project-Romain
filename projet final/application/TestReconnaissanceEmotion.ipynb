{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1;à l’aise;1'] ['2;absorbé;1'] ['3;adouci;1'] ..., ['1332;prudent;10']\n",
      " ['1333;quelconque;10'] ['1334;terne;10']]\n"
     ]
    }
   ],
   "source": [
    "import csv as csv \n",
    "import numpy as np\n",
    "\n",
    "# Open up the csv file in to a Python object\n",
    "data_all = []\n",
    "with open('motEmo.csv',encoding=\"utf8\") as train_file:\n",
    "    csv_reader = csv.reader(train_file, delimiter=',', quotechar='\"')\n",
    "    for row in csv_reader:\n",
    "        data_all.append(row)\n",
    "data_all = np.array(data_all)\n",
    "data = data_all[1::]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#importation des fichiers CSV\n",
    "dfMotEmo = pd.read_csv('motEmo.csv',encoding=\"utf-8-sig\",delimiter=\";\",header=0)\n",
    "dfMotEmoAncien = pd.read_csv('motEmo(initial).csv',encoding=\"utf-8-sig\",delimiter=\";\",header=0)\n",
    "dfEmoCat = pd.read_csv('emoCat.csv',encoding=\"utf-8-sig\",delimiter=\";\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>categorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tranquilité</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surprise</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joie</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tristesse</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dégoût</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colère</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fureur</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Peur</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Terreur</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Coupure avec ses émotions</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     emotion  categorie\n",
       "0                tranquilité          1\n",
       "1                   Surprise          2\n",
       "2                       Joie          3\n",
       "3                  Tristesse          4\n",
       "4                     Dégoût          5\n",
       "5                     Colère          6\n",
       "6                     Fureur          7\n",
       "7                       Peur          8\n",
       "8                    Terreur          9\n",
       "9  Coupure avec ses émotions         10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEmoCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571    6.0\n",
       "Name: categorie, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMotEmo[dfMotEmo['expression']=='énervé']['categorie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "data_X_train=dfMotEmo['id'].to_frame()\n",
    "data_y_train=dfMotEmo['categorie'].to_frame()\n",
    "\n",
    "#data_X_train=dfEmoCat['categorie'].to_frame()\n",
    "#data_y_train=dfEmoCat['emotion'].to_frame()\n",
    "\n",
    "#logreg.fit(data_X_train, data_y_train)\n",
    "\n",
    "\n",
    "#autre test de mahine learning\n",
    "table= dfMotEmo[['expression','categorie']].as_matrix()\n",
    "labeled_names = ([({'nom': name[0]}, name[1]) for name in table])\n",
    "import random\n",
    "random.shuffle(labeled_names)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e67cd0db5bf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m518\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Romain\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Romain\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coef_'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             raise NotFittedError(\"This %(name)s instance is not fitted \"\n\u001b[0;32m--> 242\u001b[0;31m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet"
     ]
    }
   ],
   "source": [
    "print(logreg.predict(518))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['je',\n",
       " 'suis',\n",
       " 'énervées',\n",
       " 'par',\n",
       " 'tous',\n",
       " 'ces',\n",
       " 'papiers,',\n",
       " 'il',\n",
       " 'me',\n",
       " 'mets',\n",
       " 'dans',\n",
       " 'tous',\n",
       " 'ses',\n",
       " 'états,',\n",
       " 'joie']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrasetest1=\"je suis énervées par tous ces papiers, il me mets dans tous ses états, joie\"\n",
    "phrasetest2=\"Vous avez tord de croire que la joie de vivre tient principalement aux rapports humains, vous vous trompez. Dieu en a mis dans tout ce qui nous entoure, on en trouve dans chaque détail, chaque petite chose de la vie quotidienne. Pour percevoir ces choses là, il suffirait de changer de point de vue. \"\n",
    "index=phrasetest1.find('par')\n",
    "print(index)\n",
    "phrasetest1.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'se'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import FrenchStemmer\n",
    "stemmer = FrenchStemmer()\n",
    "stemmer.stem('ses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tapez 1 pour lancer le test\n",
      "tapez 2 pour ajouter un mot ou une expression associé à une émotion à la base de donnée\n",
      "tapez \"q\" pour quitter l'application\n",
      "tapez la commande:q\n",
      "fin du programme\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "#stemming pour du francais\n",
    "stemmer = FrenchStemmer()\n",
    "french_stopwords = set(stopwords.words('french'))\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "#nombre de ligne dans la table dfMotEmo\n",
    "compteur=len(dfMotEmo.index)\n",
    "\n",
    "rest=True;\n",
    "while(rest):\n",
    "    print('tapez 1 pour lancer le test')\n",
    "    print('tapez 2 pour ajouter un mot ou une expression associé à une émotion à la base de donnée')\n",
    "    print('tapez \"q\" pour quitter l\\'application')\n",
    "    inp=input('tapez la commande:')\n",
    "    \n",
    "    if inp=='1':\n",
    "        \n",
    "        texte=input(\"Entrez la texte à tester : \");\n",
    "        #texte=phrasetest1\n",
    "        res=[]\n",
    "        #split=phrasetest1.split()\n",
    "        split=texte.split()\n",
    "        for mot in split:\n",
    "            #nettoyage des données: j'enlève les ponctuations\n",
    "            ponctuation=['.',',',';',':','!','?',')','(','\\'','\"']\n",
    "            for p in ponctuation:\n",
    "                if mot[0]==p:\n",
    "                    mot=mot[1:]\n",
    "                if mot[-1]==p:\n",
    "                    mot=mot[:-1]\n",
    "            #nettoyage des données: j'enleve les genres sur un mot pour qu'il soit reconnu dans la BDD\n",
    "            if mot[-3:]==\"ées\" or mot[-3:]==\"és\" :\n",
    "                mot=mot[:-3]+\"é\"\n",
    "            if mot[-1:]==\"s\":\n",
    "                mot=mot[:-1]\n",
    "            #recherche dans la table des expression par emotion\n",
    "            for expr in dfMotEmo['expression']:\n",
    "                if stemmer.stem(expr)==stemmer.stem(mot):\n",
    "                    id=dfMotEmo[dfMotEmo['expression']==expr]['id']\n",
    "                    res.append([expr,id])\n",
    "        #si c'est une expression de plusieurs mots\n",
    "        textLessPron=tokenizer.tokenize(texte)\n",
    "        textLessPron = [token for token in textLessPron if token.lower() not in french_stopwords]\n",
    "        for expr in dfMotEmo['expression']:\n",
    "            if len(expr.split()) > 1:\n",
    "                #on enleve les pronoms\n",
    "                exprLessPron=tokenizer.tokenize(expr)\n",
    "                exprLessPron = [token for token in exprLessPron if token.lower() not in french_stopwords] \n",
    "                #on reconstruit le texte et l'expression nettoyés\n",
    "                str1 = ' '.join(textLessPron)\n",
    "                str2 = ' '.join(exprLessPron)\n",
    "                #if texte.find(expr) != -1:\n",
    "                if str1.find(str2) != -1:\n",
    "                    print(expr)\n",
    "                    cat=dfMotEmo[dfMotEmo['expression']==expr]['id']\n",
    "                    res.append([expr,id])\n",
    "                \n",
    "        print(res)\n",
    "        #prediction pour chaque mot et expression trouvés\n",
    "        tabResultat=[]\n",
    "        for r in res:\n",
    "            #cat=logreg.predict(r[1])\n",
    "            cat=classifier.classify({'nom':r[0]})\n",
    "            print(cat)\n",
    "            print(dfEmoCat[dfEmoCat['categorie']==cat]['emotion'])\n",
    "            tabResultat.append(cat)\n",
    "        #compte le nombre d'occurence pour chaque émotions trouvées\n",
    "        print('table des id des émotions trouvées: ',tabResultat)\n",
    "        compte = {}.fromkeys(set(tabResultat),0)\n",
    "        for valeur in tabResultat:\n",
    "            compte[valeur] += 1\n",
    "        #prends l'occurence la plus haute\n",
    "        n1=0\n",
    "        for valeur in tabResultat:\n",
    "            if compte[valeur] > n1:\n",
    "                resu=valeur\n",
    "                n1=compte[valeur]\n",
    "        print('id de l\\'emotion retenu (la plus grande occurence) :', resu)\n",
    "        resu=dfEmoCat[dfEmoCat['categorie']==resu]['emotion'].values\n",
    "        print('---------------RESULTAT----------------')\n",
    "        print(resu[0])\n",
    "        print('---------------RESULTAT----------------')\n",
    "        print('')\n",
    "        print('')\n",
    "        \n",
    "    if inp=='2':\n",
    "            compteur=compteur+1\n",
    "            exprAsave=input(\"Entrez l'expression ou le mot : \");\n",
    "            print('table des émotions:')\n",
    "            print('tranquilité = 1, Surprise=2, Joie=3, Tristesse=4, Dégoût=5, Colère=6, Fureur=7, Peur=8, Terreur=9, Coupure avec ses émotions=10')\n",
    "            catAsave=input(\"Entrez le numéro de l\\'émotion : \");\n",
    "            fields=[compteur,exprAsave,catAsave]\n",
    "            #ouverture du fichier\n",
    "            with open(r'motEmo.csv', 'a',newline=\"\\n\") as f:\n",
    "                writer = csv.writer(f,delimiter=';')\n",
    "                #ajout d'une nouvelle ligne\n",
    "                writer.writerow(fields)\n",
    "            print('')\n",
    "            print('')\n",
    "            \n",
    "            \n",
    "    if inp=='q':\n",
    "        rest=False\n",
    "        print('fin du programme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Romain\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(data_X_train, data_y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(897)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taper la commande:1\n"
     ]
    }
   ],
   "source": [
    "rest=True;\n",
    "while(rest):\n",
    "    inp=input('taper la commande:')\n",
    "    if inp=='1':\n",
    "        rest=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',mot'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mot=',mot;'\n",
    "mot[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import names\n",
    "\n",
    "table= dfMotEmo[['expression','categorie']].as_matrix()\n",
    "labeled_names = ([({'nom': name[0]}, name[1]) for name in table])\n",
    "import random\n",
    "random.shuffle(labeled_names)\n",
    "\n",
    "\n",
    "\n",
    "#featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "#train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify({'nom':'traumatisé'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "Peur\n"
     ]
    }
   ],
   "source": [
    "cat=classifier.classify({'nom':'terreur'})\n",
    "print(cat)\n",
    "resu=dfEmoCat[dfEmoCat['categorie']==cat]['emotion'].values\n",
    "print(resu[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148425787106447\n"
     ]
    }
   ],
   "source": [
    "table= dfMotEmo[['expression','categorie']].as_matrix()\n",
    "labeled_names = ([({'nom': name[0]}, name[1]) for name in table])\n",
    "import random\n",
    "random.shuffle(labeled_names)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(labeled_names)\n",
    "print(nltk.classify.accuracy(classifier, labeled_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8197088465845465\n"
     ]
    }
   ],
   "source": [
    "table= dfMotEmoAncien[['expression','categorie']].as_matrix()\n",
    "labeled_names = ([({'nom': name[0]}, name[1]) for name in table])\n",
    "import random\n",
    "random.shuffle(labeled_names)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(labeled_names)\n",
    "print(nltk.classify.accuracy(classifier, labeled_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
