{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#si nltk non installé\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tapez 1 pour lancer le test\n",
      "tapez 2 pour ajouter un mot ou une expression associé à une émotion à la base de donnée\n",
      "tapez \"q\" pour quitter l'application\n",
      "tapez la commande:1\n",
      "Entrez la texte à tester : l'amour de la vie\n",
      "[]\n",
      "---------------RESULTAT----------------\n",
      "neutre\n",
      "---------------RESULTAT----------------\n",
      "\n",
      "\n",
      "tapez 1 pour lancer le test\n",
      "tapez 2 pour ajouter un mot ou une expression associé à une émotion à la base de donnée\n",
      "tapez \"q\" pour quitter l'application\n",
      "tapez la commande:amour de la vie\n",
      "tapez 1 pour lancer le test\n",
      "tapez 2 pour ajouter un mot ou une expression associé à une émotion à la base de donnée\n",
      "tapez \"q\" pour quitter l'application\n",
      "tapez la commande:1\n",
      "Entrez la texte à tester : amour de la vie\n",
      "[['amoureux', 241    242\n",
      "Name: id, dtype: int64], ['amour', 242    243\n",
      "Name: id, dtype: int64]]\n",
      "3.0\n",
      "2    Joie\n",
      "Name: emotion, dtype: object\n",
      "3.0\n",
      "2    Joie\n",
      "Name: emotion, dtype: object\n",
      "table des id des émotions trouvées:  [3.0, 3.0]\n",
      "id de l'emotion retenu (la plus grande occurence) : 3.0\n",
      "---------------RESULTAT----------------\n",
      "Joie\n",
      "---------------RESULTAT----------------\n",
      "\n",
      "\n",
      "[['amoureux', 241    242\n",
      "Name: id, dtype: int64], ['amour', 242    243\n",
      "Name: id, dtype: int64], ['amoureux', 241    242\n",
      "Name: id, dtype: int64], ['amour', 242    243\n",
      "Name: id, dtype: int64]]\n",
      "3.0\n",
      "2    Joie\n",
      "Name: emotion, dtype: object\n",
      "3.0\n",
      "2    Joie\n",
      "Name: emotion, dtype: object\n",
      "3.0\n",
      "2    Joie\n",
      "Name: emotion, dtype: object\n",
      "3.0\n",
      "2    Joie\n",
      "Name: emotion, dtype: object\n",
      "table des id des émotions trouvées:  [3.0, 3.0, 3.0, 3.0]\n",
      "id de l'emotion retenu (la plus grande occurence) : 3.0\n",
      "tapez 1 pour lancer le test\n",
      "tapez 2 pour ajouter un mot ou une expression associé à une émotion à la base de donnée\n",
      "tapez \"q\" pour quitter l'application\n"
     ]
    }
   ],
   "source": [
    "import csv as csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn import linear_model, datasets\n",
    "import random\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import nltk.data\n",
    "\n",
    "#importation des fichiers CSV\n",
    "dfMotEmo = pd.read_csv('motEmo.csv',encoding=\"utf-8-sig\",delimiter=\";\",header=0)\n",
    "dfEmoCat = pd.read_csv('emoCat.csv',encoding=\"utf-8-sig\",delimiter=\";\",header=0)\n",
    "\n",
    "\n",
    "#création du model d'apprentissage\n",
    "table= dfMotEmo[['expression','categorie']].as_matrix()\n",
    "labeled_names = ([({'nom': name[0]}, name[1]) for name in table])\n",
    "random.shuffle(labeled_names)\n",
    "classifier = nltk.NaiveBayesClassifier.train(labeled_names)\n",
    "\n",
    "#stemming pour du francais\n",
    "stemmer = FrenchStemmer()\n",
    "french_stopwords = set(stopwords.words('french'))\n",
    "tokenizer = WordPunctTokenizer()\n",
    "tokenizerPhrase = nltk.data.load('tokenizers/punkt/french.pickle')\n",
    "\n",
    "#nombre de ligne dans la table dfMotEmo\n",
    "compteur=len(dfMotEmo.index)\n",
    "\n",
    "def nettoyageEtRechercheDonnee(texte,donnee):\n",
    "    split=texte.split()\n",
    "    for mot in split:\n",
    "        #nettoyage des données: j'enlève les ponctuations\n",
    "        ponctuation=['.',',',';',':','!','?',')','(','\\'','\"']\n",
    "        for p in ponctuation:\n",
    "            if mot[0]==p:\n",
    "                mot=mot[1:]\n",
    "            if mot[-1]==p:\n",
    "                mot=mot[:-1]\n",
    "        #nettoyage des données: j'enleve donneeles genres sur un mot pour qu'il soit reconnu dans la BDD\n",
    "        if mot[-3:]==\"ées\" or mot[-3:]==\"és\" :\n",
    "            mot=mot[:-3]+\"é\"\n",
    "        if mot[-1:]==\"s\":\n",
    "            mot=mot[:-1]\n",
    "        #recherche dans la table des expression par emotion\n",
    "        for expr in donnee['expression']:\n",
    "            if stemmer.stem(expr)==stemmer.stem(mot):\n",
    "                id=donnee[donnee['expression']==expr]['id']\n",
    "                res.append([expr,id])\n",
    "    #si c'est une expression de plusieurs mots\n",
    "    textLessPron=tokenizer.tokenize(texte)\n",
    "    textLessPron = [token for token in textLessPron if token.lower() not in french_stopwords]\n",
    "    for expr in donnee['expression']:\n",
    "        if len(expr.split()) > 1:\n",
    "            #on enleve les pronoms\n",
    "            exprLessPron=tokenizer.tokenize(expr)\n",
    "            exprLessPron = [token for token in exprLessPron if token.lower() not in french_stopwords] \n",
    "            #on reconstruit le texte et l'expression nettoyés\n",
    "            str1 = ' '.join(textLessPron)\n",
    "            str2 = ' '.join(exprLessPron)\n",
    "            #if texte.find(expr) != -1:\n",
    "            if str1.find(str2) != -1:\n",
    "                print(expr)\n",
    "                cat=donnee[donnee['expression']==expr]['id']\n",
    "                res.append([expr,id])\n",
    "    print(res)\n",
    "    return res;\n",
    "\n",
    "def prediction(donnee):\n",
    "    tabResultat=[]\n",
    "    for r in donnee:\n",
    "        #cat=logreg.predict(r[1])\n",
    "        cat=classifier.classify({'nom':r[0]})\n",
    "        print(cat)\n",
    "        print(dfEmoCat[dfEmoCat['categorie']==cat]['emotion'])\n",
    "        tabResultat.append(cat)\n",
    "    #compte le nombre d'occurence pour chaque émotions trouvées\n",
    "    print('table des id des émotions trouvées: ',tabResultat)\n",
    "    compte = {}.fromkeys(set(tabResultat),0)\n",
    "    for valeur in tabResultat:\n",
    "        compte[valeur] += 1\n",
    "    #prends l'occurence la plus haute\n",
    "    n1=0\n",
    "    for valeur in tabResultat:\n",
    "        if compte[valeur] > n1:\n",
    "            resu=valeur\n",
    "            n1=compte[valeur]\n",
    "    print('id de l\\'emotion retenu (la plus grande occurence) :', resu)\n",
    "    resu=dfEmoCat[dfEmoCat['categorie']==resu]['emotion'].values\n",
    "    return resu[0];\n",
    "\n",
    "def apprentAuto(texte,compteur,tokenizer,donnee):\n",
    "    # chargement du tokenizer\n",
    "    tokens = tokenizer.tokenize(texte)\n",
    "    for phrase in tokens:\n",
    "        res=nettoyageEtRechercheDonnee(phrase,donnee)\n",
    "        resu=prediction(res)\n",
    "        categorie=dfEmoCat[dfEmoCat['emotion']==resu]['categorie'].values\n",
    "        compteur=compteur+1\n",
    "        fields=[compteur,phrase,categorie[0]]\n",
    "        #ouverture du fichier\n",
    "        with open(r'motEmo.csv', 'a',newline=\"\\n\") as f:\n",
    "            writer = csv.writer(f,delimiter=';')\n",
    "            #ajout d'une nouvelle ligne\n",
    "            writer.writerow(fields)\n",
    "    return compteur;\n",
    "    \n",
    "    \n",
    "#programme principal\n",
    "rest=True;\n",
    "while(rest):\n",
    "    print('tapez 1 pour lancer le test')\n",
    "    print('tapez 2 pour ajouter un mot ou une expression associé à une émotion à la base de donnée')\n",
    "    print('tapez \"q\" pour quitter l\\'application')\n",
    "    inp=input('tapez la commande:')\n",
    "    \n",
    "    if inp=='1':\n",
    "        \n",
    "        texte=input(\"Entrez la texte à tester : \");\n",
    "        res=[]\n",
    "        #nettoyage des données\n",
    "        tableDonnee=nettoyageEtRechercheDonnee(texte,dfMotEmo)\n",
    "        #prediction pour chaque mot et expression trouvés\n",
    "        if tableDonnee == []:\n",
    "            resultat='neutre'\n",
    "        else:\n",
    "            resultat=prediction(tableDonnee)\n",
    "        print('---------------RESULTAT----------------')\n",
    "        print(resultat)\n",
    "        print('---------------RESULTAT----------------')\n",
    "        print('')\n",
    "        print('')\n",
    "        #apprentissage auto\n",
    "        if tableDonnee != []:\n",
    "            compteur=apprentAuto(texte,compteur,tokenizerPhrase,dfMotEmo);\n",
    "        \n",
    "    if inp=='2':\n",
    "            compteur=compteur+1\n",
    "            exprAsave=input(\"Entrez l'expression ou le mot : \");\n",
    "            print('table des émotions:')\n",
    "            print('tranquilité = 1, Surprise=2, Joie=3, Tristesse=4, Dégoût=5, Colère=6, Fureur=7, Peur=8, Terreur=9, Coupure avec ses émotions=10')\n",
    "            catAsave=input(\"Entrez le numéro de l\\'émotion : \");\n",
    "            fields=[compteur,exprAsave,catAsave]\n",
    "            #ouverture du fichier\n",
    "            with open(r'motEmo.csv', 'a',newline=\"\\n\") as f:\n",
    "                writer = csv.writer(f,delimiter=';')\n",
    "                #ajout d'une nouvelle ligne\n",
    "                writer.writerow(fields)\n",
    "            print('')\n",
    "            print('')\n",
    "            \n",
    "            \n",
    "    if inp=='q':\n",
    "        rest=False\n",
    "        print('fin du programme')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
